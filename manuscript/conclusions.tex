\section{Conclusions}

In this work, we were able to develop a fast equivalent layer technique for processing magnetic data with the method of Conjugate Gradient Least Square using the convolutional equivalent layer theory to obtain results of performance more than four orders of magnitude less than the classical equivalent layer. The sensitivity matrix of the magnetic equivalent layer carries the structure of BTTB matrices, which means a very low computational cost matrix-vector product and also the possibility to store only the first column of the matrix BCCB. In this work we propose a novel method to use only one equivalent source and calculating the first six columns of the inverse of distance second derivatives matrices to arrive in the first column of the BCCB matrix embbeded from the original magnetic kernel sensitivity matrix.

Synthetic tests showed similar results estimating the physical property using a classical approach to solve a linear system and our method using the CGLS combined with the BTTB matrix-vector product. The difference in time, however, is noticeable: $2.04$ seconds using the classical approach and $0.083$ seconds using our approach. This difference was obtained with a mid-size mesh of $80 \times 80$ points, greater results can be obtained if more observation points are used.

Real data test were also conducted in the region of Carajás, Pará, Brazil. With an irregular grid of $1,310,000$ observation points, store the full sensitivity matrix it would be necessary $12.49$ Terabytes of RAM.  However, taking advantage of the symmetric or skew-symmetric matrices structures, it is possible to reconstruct the whole sensitivity matrix using only $59.97$ Megabytes.
Using 200 iterations of the CGLS method took $385.56$ seconds and very good results of property estimative were obtained. Also the upward-continuation transformation showed good results and took only $2.64$ seconds.