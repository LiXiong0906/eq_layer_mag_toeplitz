\begin{abstract}

We present a fast equivalent layer for processing large-scale magnetic data. 
Taking advantage of the sensitivity matrix structure of the magnetic kernel, when observation and equivalent sources are aligned on a regular spaced grid with constant height, we can calculate the matrix-vector product in a very fast manner. 
In the literature, this matrix structure is called block-Toeplitz Toeplitz-block (BTTB) that can be embbeded 
into a block-Circulant Circulant-block (BCCB), which in turn has its eigenvalues calculated using only the first column of the BTTB matrix and a 2D fast Fourier transform. 
We demonstrate that, despite this BTTB matrix is not symmetric, by using only the first equivalent source it is possible to calculate all the first columns of the inverse of distance second derivatives that compose the magnetic kernel and reconstruct the first column of the BCCB matrix, saving computational time and system memory. 
We solve the linear system by modifying the conjugate gradient iterative method to estimate the 
physical-property distribution over the equivalent layer and then to process large data sets.
Synthetic tests show a decrease in the order of $10^4$ in floating-point operations, $25$ times in computation runtime with a mid-size $80 \times 80$ grid, and exponential decrease in memory RAM usage, allowing to perform this operation with millions of observations on desktop computers. 
Synthetic tests simulating data on irregular grids or over undulating observation surfaces  show the robustness of the convolutional equivalent layer in processing magnetic surveys that violate the requirement  that the data be measured on a regular grid and the observation surface be planar.
Test on real magnetic data from Caraj{\'a}s Province, Brazil, with $1,310,000$ observations on an irregular grid, confirms the success of our method, taking $385.56$ seconds to estimate the physical-property distribution over the equivalent layer and $2.64$ seconds for upward-continuing the data.

\end{abstract}